{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Recommender System with Spotify Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import argparse\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from collections import defaultdict\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import cdist\n",
    "from pprint import pprint\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from kneed import KneeLocator\n",
    "sns.set()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mainpulating Spotify Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data = pd.read_csv('./data/us_charts_with_audio_features.csv')\n",
    "spotify_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with invalid values\n",
    "spotify_data.dropna(inplace=True)\n",
    "\n",
    "# Select a subset of columns to use in the clustering process\n",
    "columns_to_use = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "X = spotify_data[columns_to_use]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_std);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evr = pca.explained_variance_ratio_\n",
    "evr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1, len(X.columns)+1), evr.cumsum(), marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Components', fontsize=18)\n",
    "plt.ylabel('Cumulative Explained Variance',fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, exp_var in enumerate(evr.cumsum()):\n",
    "    if exp_var >= 0.8:\n",
    "        n_comps = i + 1\n",
    "        break\n",
    "print(\"Number of components:\", n_comps)\n",
    "pca = PCA(n_components=n_comps)\n",
    "pca.fit(X_std)\n",
    "scores_pca = pca.transform(X_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the elbow point of the WCSS (within cluster sum of squares) curve using the YellowBrick KElbowVisualizer\n",
    "visualizer = KElbowVisualizer(KMeans(init='k-means++', random_state=42), k=(1,21), timings=False)\n",
    "visualizer.fit(scores_pca)\n",
    "visualizer.show()\n",
    "n_clusters = visualizer.elbow_value_\n",
    "print(\"Optimal number of clusters:\", n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the elbow point of the WCSS (within cluster sum of squares) curve using the kneed KneeLocator\n",
    "wcss = []\n",
    "max_clusters = 21\n",
    "for i in range(1, max_clusters):\n",
    "    kmeans_pca = KMeans(i, init='k-means++', random_state=42)\n",
    "    kmeans_pca.fit(scores_pca)\n",
    "    wcss.append(kmeans_pca.inertia_)\n",
    "n_clusters = KneeLocator([i for i in range(1, max_clusters)], wcss, curve='convex', direction='decreasing').knee\n",
    "print(\"Optimal number of clusters\", n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1, 21), wcss, marker='o', linestyle='--')\n",
    "plt.vlines(KneeLocator([i for i in range(1, max_clusters)], wcss, curve='convex', direction='decreasing').knee, ymin=min(wcss), ymax=max(wcss), linestyles='dashed')\n",
    "plt.xlabel('Number of Clusters', fontsize=18)\n",
    "plt.ylabel('Within Cluster Sum of Squares (WCSS)', fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pca = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42)\n",
    "kmeans_pca.fit(scores_pca);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg_pca_kmeans = pd.concat([X.reset_index(drop=True), pd.DataFrame(scores_pca)], axis=1)\n",
    "df_seg_pca_kmeans.columns.values[(-1*n_comps):] = [\"Component \" + str(i+1) for i in range(n_comps)]\n",
    "df_seg_pca_kmeans['Cluster'] = kmeans_pca.labels_\n",
    "df_seg_pca_kmeans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df_seg_pca_kmeans['Component 2']\n",
    "# y = df_seg_pca_kmeans['Component 1']\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df_seg_pca_kmeans, x='Component 2', y='Component 1', hue=df_seg_pca_kmeans['Cluster'], palette = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'goldenrod', 'tab:cyan'])\n",
    "plt.title('Clusters by PCA Components', fontsize=20)\n",
    "plt.xlabel(\"Component 2\", fontsize=18)\n",
    "plt.ylabel(\"Component 1\", fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data['cluster_label'] = df_seg_pca_kmeans['Cluster']\n",
    "spotify_data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Song Clusters with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for dimension reduction (faster than t-SNE)\n",
    "pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\n",
    "song_embedding = pca_pipeline.fit_transform(X)\n",
    "\n",
    "projection = pd.DataFrame(columns=['x', 'y'], data=song_embedding)\n",
    "projection['title'] = spotify_data['name']\n",
    "projection['cluster'] = spotify_data['cluster_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize song clusters in a 2D space\n",
    "fig = px.scatter(\n",
    "    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Content-Based Recommender System"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish spotipy connection\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=os.environ[\"SPOTIFY_CLIENT_ID\"],\n",
    "                                                           client_secret=os.environ[\"SPOTIFY_CLIENT_SECRET\"]))\n",
    "\n",
    "# Returns a dataframe with data for a song given the name and artist.\n",
    "# Uses Spotipy to fetch audio features and metadata for the specified song.\n",
    "def find_song(name, artist):\n",
    "    song_data = defaultdict()\n",
    "    results = sp.search(q= 'track: {} artist: {}'.format(name, artist), type='track', limit=1)\n",
    "    if results['tracks']['items'] == []:\n",
    "        return None\n",
    "    \n",
    "    results = results['tracks']['items'][0]\n",
    "\n",
    "    track_id = results['id']\n",
    "    audio_features = sp.audio_features(track_id)[0]\n",
    "    \n",
    "    song_data['name'] = [name]\n",
    "    song_data['artists'] = [artist]\n",
    "    \n",
    "    for key, value in audio_features.items():\n",
    "        song_data[key] = value\n",
    "    \n",
    "    return pd.DataFrame(song_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the song data for a specific song\n",
    "# Song argument is a dictionary with key-value pairs for the name and artist\n",
    "def get_song_data(song, spotify_data):\n",
    "    # Check if song is in the spotify dataset, otherwise use find_song method\n",
    "    try:\n",
    "        song_data = spotify_data[(spotify_data['name'] == song['name']) \n",
    "                                & (spotify_data['artists'] == song['artist'])].iloc[0]\n",
    "        return song_data\n",
    "    except IndexError:\n",
    "        return find_song(song['name'], song['artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates mean vector from a list of songs based on audio/metadata features\n",
    "def get_mean_vector(song_list, spotify_data):\n",
    "    song_vectors = []\n",
    "    \n",
    "    # Add all songs to song_vectors\n",
    "    for song in song_list:\n",
    "        song_data = get_song_data(song, spotify_data)\n",
    "        if song_data is None:\n",
    "            print('Warning: {} does not exist in Spotify or in database'.format(song['name']))\n",
    "            continue\n",
    "        song_vector = song_data[columns_to_use].values\n",
    "        song_vectors.append(song_vector)\n",
    "    \n",
    "    # Convert to numpy array then use np.mean\n",
    "    song_matrix = np.array(list(song_vectors))\n",
    "    return np.mean(song_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattens a list of dictionaries.\n",
    "def flatten_dict_list(dict_list):\n",
    "    flattened_dict = defaultdict()\n",
    "    for key in dict_list[0].keys():\n",
    "        flattened_dict[key] = []\n",
    "    \n",
    "    for dictionary in dict_list:\n",
    "        for key, value in dictionary.items():\n",
    "            flattened_dict[key].append(value)\n",
    "            \n",
    "    return flattened_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommends songs based on a list of previous songs that a user has listened to.\n",
    "def recommend_songs(song_list, spotify_data, n_songs=10):\n",
    "    # Compute average vector of input songs\n",
    "    song_center = get_mean_vector(song_list, spotify_data)\n",
    "\n",
    "    # Scale the data\n",
    "    scaled_data = scaler.transform(spotify_data[columns_to_use])\n",
    "    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n",
    "\n",
    "    # Find closest songs in dataset to the average vector using cosine distance\n",
    "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
    "    index = list(np.argsort(distances)[:, :n_songs][0])\n",
    "    \n",
    "    # Recommend corresponding songs from the dataset\n",
    "    rec_songs = spotify_data.iloc[index]\n",
    "    song_dict = flatten_dict_list(song_list)\n",
    "    rec_songs = rec_songs[~rec_songs['name'].isin(song_dict['name'])]\n",
    "\n",
    "    # Format output\n",
    "    metadata_cols = ['name', 'artists', 'url']\n",
    "    return rec_songs[metadata_cols].to_dict(orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_songs([{'name': 'HiTek Tek', 'artist': 'Future'},\n",
    "                {'name': 'Ridin Strikers', 'artist': 'Future'},\n",
    "                {'name': 'Touch The Sky', 'artist': 'Future'},\n",
    "                {'name': 'One Of My', 'artist': 'Future'},\n",
    "                {'name': 'Hard To Choose One', 'artist': 'Future'},\n",
    "                {'name': 'Solitaires (feat. Travis Scott)', 'artist': 'Future'},\n",
    "                {'name': 'Harlem Shake (feat. Young Thug)', 'artist': 'Future'},\n",
    "                {'name': 'Too Comfortable', 'artist': 'Future'}], spotify_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_songs([{'name': 'SAD!', 'artist': 'XXXTentacion'},\n",
    "                {'name': 'Lucid Dreams', 'artist': 'Juice WRLD'},\n",
    "                {'name': 'All Girls Are The Same', 'artist': 'Juice WRLD'},\n",
    "                {'name': 'Jocelyn Flores', 'artist': 'XXXTentacion'},\n",
    "                {'name': 'Fuck Love (feat. Trippie Redd)', 'artist': 'XXXTentacion'},\n",
    "                {'name': 'Hope', 'artist': 'XXXTentacion'}], spotify_data, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "44a9cdcbdccbf05a880e90d2e6fe72470baab4d1b82472d890be0596ed887a6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
